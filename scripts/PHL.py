import re
import unicodedata
from typing import Dict, List

def normalize(text: str) -> str:
    """
    è²å¾‹å®¾è¯­å®Œæ•´è§„èŒƒåŒ–è„šæœ¬ï¼ˆä¿®æ­£ç‰ˆï¼‰
    
    ä¸»è¦åŠŸèƒ½ï¼š
    1. é‡å¤å­—æ¯å®Œå…¨å½’çº¦ï¼ˆsobrang â†’ sobrangï¼‰
    2. æ™ºèƒ½ç¼©å†™å±•å¼€ï¼ˆ'yung â†’ ang, d'yan â†’ diyanï¼‰
    3. å¤–æ¥è¯æ ‡å‡†åŒ–ï¼ˆcafÃ© â†’ cafe, azÃºcar â†’ asukalï¼‰
    4. æ ‡ç‚¹/ç©ºæ ¼æ¸…ç†
    5. URL/ç”µå­é‚®ä»¶ä¿æŠ¤
    
    ç¤ºä¾‹ï¼š
    >>> normalize("Sobrang inittt 'yung cafÃ© sa d'yan!")
    "Sobrang init ang cafe sa diyan!"
    """
    if not text.strip():
        return text

    # é¢„å¤„ç†ï¼šä¿æŠ¤URL/ç”µå­é‚®ä»¶
    protected_spans = []
    text = protect_special_content(text, protected_spans)
    
    # å¤„ç†é¡ºåºï¼ˆé‡è¦ï¼ï¼‰
    text = remove_accents(text)                  # å…ˆå»é‡éŸ³
    text = reduce_repeated_characters(text)      # å†å»é‡å­—æ¯
    text = expand_contractions(text)             # ç„¶åå±•å¼€ç¼©å†™
    text = standardize_spelling(text)            # æœ€åæ ‡å‡†åŒ–æ‹¼å†™
    
    # åå¤„ç†
    text = restore_protected_content(text, protected_spans)
    text = clean_text(text)
    
    text = text.upper()
    
    return text

def protect_special_content(text: str, protected_spans: List) -> str:
    """ä¿æŠ¤URLå’Œç”µå­é‚®ä»¶"""
    for pattern in [r'https?://\S+', r'\b[\w.-]+@[\w.-]+\.\w+\b']:
        for match in re.finditer(pattern, text):
            protected_spans.append({
                'start': match.start(),
                'end': match.end(),
                'original': match.group()
            })
            text = text[:match.start()] + f" ğ™‹ğ™ğ™Šğ™ğ™€ğ˜¾ğ™ğ™€ğ˜¿_{len(protected_spans)-1} " + text[match.end():]
    return text

def restore_protected_content(text: str, protected_spans: List) -> str:
    """æ¢å¤è¢«ä¿æŠ¤çš„å†…å®¹"""
    for i, span in enumerate(protected_spans):
        text = text.replace(f"ğ™‹ğ™ğ™Šğ™ğ™€ğ˜¾ğ™ğ™€ğ˜¿_{i}", span['original'])
    return text

def remove_accents(text: str) -> str:
    """ç§»é™¤é‡éŸ³ç¬¦å·ï¼ˆÃ© â†’ eï¼‰"""
    return unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8')

def reduce_repeated_characters(text: str) -> str:
    """é‡å¤å­—æ¯å®Œå…¨å½’çº¦"""
    return re.sub(r'([a-zA-Z])\1+', r'\1', text)

def expand_contractions(text: str) -> str:
    """è²å¾‹å®¾è¯­ç¼©å†™å±•å¼€ï¼ˆä¼˜å…ˆçº§ä»é«˜åˆ°ä½ï¼‰"""
    CONTRACTIONS = {
        # æ•´ä½“æ›¿æ¢ä¼˜å…ˆ
        r"'yung\b": "ang",   # 'yung â†’ ang
        r"'yng\b": "ang",    # 'yng â†’ ang
        r"'ung\b": "ang",    # 'ung â†’ ang
        r"d'yan\b": "diyan", # d'yan â†’ diyan
        r"n'ung\b": "ng",    # n'ung â†’ ng
        
        # é€šç”¨è§„åˆ™
        r"'y\b": "ang",     # 'y â†’ ang
        r"'t\b": "at",      # 't â†’ at
        r"'n\b": "ng",      # 'n â†’ ng
        r"'di\b": "hindi",  # 'di â†’ hindi
        r"'pag\b": "kapag", # 'pag â†’ kapag
    }
    
    for pattern, replacement in CONTRACTIONS.items():
        text = re.sub(pattern, replacement, text, flags=re.IGNORECASE)
    
    return text

def standardize_spelling(text: str) -> str:
    """æ ‡å‡†åŒ–æ‹¼å†™ï¼ˆå«å¤§å°å†™æ„ŸçŸ¥ï¼‰"""
    SPELLING_VARIANTS = {
        'azucar': 'asukal',
        'kompyuter': 'komputer',  # ä¸¤ç§æ‹¼å†™çš†å¯
        'pamilya': 'pamilya',
        'nang': 'ng',             # åŒºåˆ†å‰¯è¯nangå’Œå±æ ¼ng
        'nang ': 'ng '
    }
    
    words = text.split()
    normalized_words = []
    
    for word in words:
        original_word = word
        word_lower = remove_accents(word.lower())
        
        # æ£€æŸ¥å˜ä½“ï¼ˆå¿½ç•¥æ ‡ç‚¹ï¼‰
        word_stem = re.sub(r'[^\w]', '', word_lower)
        if word_stem in SPELLING_VARIANTS:
            normalized_word = adjust_case(word, SPELLING_VARIANTS[word_stem])
            # ä¿ç•™åŸå§‹æ ‡ç‚¹
            punctuation = re.sub(r'[\w]', '', original_word)
            normalized_words.append(normalized_word + punctuation)
        else:
            normalized_words.append(word)
    
    return ' '.join(normalized_words)

def adjust_case(original: str, replacement: str) -> str:
    """æ™ºèƒ½å¤§å°å†™è½¬æ¢"""
    if original.isupper():
        return replacement.upper()
    elif original.istitle():
        return replacement.capitalize()
    return replacement.lower()

def clean_text(text: str) -> str:
    """æœ€ç»ˆæ¸…ç†"""
    text = re.sub(r'([.,!?])\1+', r'\1', text)  # é‡å¤æ ‡ç‚¹
    text = re.sub(r'\s+', ' ', text)            # å¤šä½™ç©ºæ ¼
    return text.strip()

def get_normalizer(language_code: str):

    if language_code.upper() in ('FIL', 'PHL'):
        return normalize
    raise ValueError(f"Unsupported language: {language_code}")
