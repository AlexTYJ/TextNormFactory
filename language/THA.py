import re
import unicodedata

def normalize(text: str) -> str:
    """
    Most complete Thai normalization for CER:
    - Unicode NFC normalization (critical for Thai tone/vowel combining order)
    - Remove bracketed content [laugh], (noise)
    - Remove zero-width characters
    - Remove only '#' symbol (not following content)
    - Remove punctuation
    - Convert English digits to Thai digits
    - Remove English/Chinese punctuations
    - Remove spaces (Thai doesn't use them for CER)
    - Keep only Thai characters + Thai digits
    - Final char-level spacing for CER
    """

    # Thai digits ‚Üí ASCII digits (012345)
    EN2TH_DIGITS = str.maketrans({
        "‡πê": "0",
        "‡πë": "1",
        "‡πí": "2",
        "‡πì": "3",
        "‡πî": "4",
        "‡πï": "5",
        "‡πñ": "6",
        "‡πó": "7",
        "‡πò": "8",
        "‡πô": "9",
    })

    ZERO_WIDTH_CHARS = r"\u200B\u200C\u200D\uFEFF"
    BRACKET_PATTERN = r"\[[^\]]*\]|\([^\)]*\)|\{[^\}]*\}"

    # 1. Unicode NFC normalization
    text = unicodedata.normalize("NFC", text)

    # 2. Remove annotation
    text = re.sub(BRACKET_PATTERN, "", text)

    # 3. Remove '#' only
    text = text.replace("#", "")

    # 4. Remove zero-width chars
    text = re.sub(f"[{ZERO_WIDTH_CHARS}]", "", text)

    # 5. Thai digits ‚Üí ASCII digits
    text = text.translate(EN2TH_DIGITS)

    # 6. Keep only Thai chars + digits
    text = re.sub(r"[^\u0E00-\u0E7F0-9]", "", text)

    # 7. Final NFC (safety)
    text = unicodedata.normalize("NFC", text)

    # ======== CER Áî®ÔºöÂ≠óÁ¨¶Á∫ßÁ©∫Ê†ºÂåñÔºàÂîØ‰∏ÄÊñ∞Â¢ûÔºâ========
    text = " ".join([ch for ch in text if ch.strip() != ""])

    return text


if __name__ == "__main__":
    for item in [
        "‡πÑ‡∏°‡πà ‡πÑ‡∏°‡πà [laugh] ‡πÑ‡∏°‡πà ‡∏´‡∏ô‡∏π‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏ï‡∏±‡πâ‡∏á‡πÉ‡∏à",
        "(‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏´‡∏±‡∏ß‡πÄ‡∏£‡∏≤‡∏∞) ‡∏Å‡πá‡πÅ‡∏ö‡∏ö‡∏ß‡πà‡∏≤ ‡∏´‡∏ô‡∏π‡∏ï‡∏Å‡πÉ‡∏à‡∏°‡∏≤‡∏Å",
        r"‡∏û‡∏µ‡πà‡πÄ‡∏Ñ‡πâ‡∏≤‡∏û‡∏π‡∏î‡∏ß‡πà‡∏≤ {breath} ‡πÄ‡∏î‡∏µ‡πã‡∏¢‡∏ß‡∏°‡∏≤‡πÅ‡∏õ‡πä‡∏ö‡∏ô‡∏∂‡∏á‡∏ô‡∏∞",
        "‡∏û‡∏≠‡∏î‡∏µ‡∏≠‡∏¢‡∏π‡πà‡∏Ç‡πâ‡∏≤‡∏á‡∏û‡∏µ‡πà‡πÅ‡∏≠‡∏ü # ‡∏≠‡πà‡∏≤ ‡∏ï‡πâ‡∏≠‡∏á‡∏£‡∏µ‡∏ö‡πÑ‡∏õ",
        "‡∏ß‡∏±‡∏ô‡∏ô‡∏µ‡πâ‡∏´‡∏ô‡∏π‡∏ï‡∏∑‡πà‡∏ô‡∏ï‡∏≠‡∏ô 7 ‡πÇ‡∏°‡∏á",
        "‡∏û‡∏µ‡πà‡∏Ñ‡∏∞ [laugh] ‡∏´‡∏ô‡∏π‡∏ñ‡∏∂‡∏á‡∏ö‡πâ‡∏≤‡∏ô‡πÅ‡∏•‡πâ‡∏ß‡∏Ñ‡πà‡∏≤‡∏≤‡∏≤~ 555 üòÇüòÇ",
        "‡πÇ‡∏≠‡πÄ‡∏Ñ‡∏Ñ‡πà‡∏∞ 100%",
        "‡πÄ‡∏Å‡πã"
    ]:
        print(f"{item}\n{normalize(item)}\n------")
